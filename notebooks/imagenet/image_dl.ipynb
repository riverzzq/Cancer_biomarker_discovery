{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800ef7f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class CFG:\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    img_size: int = 224\n",
    "    batch_size: int = 64\n",
    "    num_workers: int = 4\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 10\n",
    "    num_classes: int = 2  # change\n",
    "    amp: bool = True\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Dataset (replace with your loader)\n",
    "# -------------------------\n",
    "class PatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects: a list of (img_path, label)\n",
    "    \"\"\"\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, y = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "def build_transforms(img_size: int):\n",
    "    # UNI generally uses ImageNet normalization for patch input\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Model\n",
    "# -------------------------\n",
    "class UNIClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # UNI backbone from Hugging Face via timm\n",
    "        # NOTE: requires HF login + accepting model terms\n",
    "        self.backbone = timm.create_model(\n",
    "            \"hf_hub:MahmoodLab/uni\",\n",
    "            pretrained=True,\n",
    "            num_classes=0,   # feature extractor (no classifier head)\n",
    "        )\n",
    "\n",
    "        # figure out embedding dim robustly\n",
    "        feat_dim = getattr(self.backbone, \"num_features\", None)\n",
    "        if feat_dim is None:\n",
    "            # timm backbones usually expose num_features; fallback:\n",
    "            with torch.no_grad():\n",
    "                dummy = torch.zeros(1, 3, 224, 224)\n",
    "                feat_dim = self.backbone(dummy).shape[-1]\n",
    "\n",
    "        # small head (edit as needed)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(feat_dim),\n",
    "            nn.Linear(feat_dim, num_classes),\n",
    "        )\n",
    "\n",
    "        # Freeze backbone by default\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)       # [B, D]\n",
    "        logits = self.head(feats)      # [B, C]\n",
    "        return logits\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Train / Eval loops\n",
    "# -------------------------\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss, correct, n = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.autocast(device_type=device.split(\":\")[0], enabled=(scaler is not None)):\n",
    "            logits = model(x)\n",
    "            loss = ce(logits, y)\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        n += x.size(0)\n",
    "\n",
    "    return total_loss / n, correct / n\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss, correct, n = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = ce(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        n += x.size(0)\n",
    "\n",
    "    return total_loss / n, correct / n\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main (skeleton)\n",
    "# -------------------------\n",
    "def main(train_samples, val_samples):\n",
    "    cfg = CFG()\n",
    "\n",
    "    tfm = build_transforms(cfg.img_size)\n",
    "    train_ds = PatchDataset(train_samples, transform=tfm)\n",
    "    val_ds   = PatchDataset(val_samples, transform=tfm)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "        num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=cfg.batch_size, shuffle=False,\n",
    "        num_workers=cfg.num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = UNIClassifier(num_classes=cfg.num_classes).to(cfg.device)\n",
    "\n",
    "    # Only train head params (backbone frozen)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        (p for p in model.parameters() if p.requires_grad),\n",
    "        lr=cfg.lr, weight_decay=1e-2\n",
    "    )\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if (cfg.amp and cfg.device.startswith(\"cuda\")) else None\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, scaler, cfg.device)\n",
    "        va_loss, va_acc = eval_one_epoch(model, val_loader, cfg.device)\n",
    "        print(f\"epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "\n",
    "    # Save only the head if you want (typical for FL)\n",
    "    torch.save(model.head.state_dict(), \"uni_head.pt\")\n",
    "    # Or save whole model state\n",
    "    torch.save(model.state_dict(), \"uni_full.pt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual split\n",
    "    # Format: [(path, label), ...]\n",
    "    train_samples = [(\"path/to/img1.png\", 0), (\"path/to/img2.png\", 1)]\n",
    "    val_samples   = [(\"path/to/img3.png\", 0)]\n",
    "    main(train_samples, val_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621d4ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
